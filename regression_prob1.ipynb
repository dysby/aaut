{
 "cells": [
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 1,
=======
   "cell_type": "markdown",
   "id": "6edd5301",
   "metadata": {},
   "source": [
    "# Regression - Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> 9c604b1 (initial commit)
   "id": "319928e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": null,
>>>>>>> 9c604b1 (initial commit)
   "id": "860a5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Training Set\n",
    "x_train = np.load(\"Xtrain_Regression_Part1.npy\")\n",
    "y_train = np.load(\"Ytrain_Regression_Part1.npy\")\n",
<<<<<<< HEAD
    "y_test = np.load(\"Xtest_Regression_Part1.npy\")"
=======
    "x_test = np.load(\"Xtest_Regression_Part1.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac5666",
   "metadata": {},
   "source": [
    "## Study Implementation"
>>>>>>> 9c604b1 (initial commit)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6b8cf",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Linear Predition"
=======
    "## Linear Predictor"
>>>>>>> 9c604b1 (initial commit)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": null,
>>>>>>> 9c604b1 (initial commit)
   "id": "01194f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember X = [1 x.T]\n",
    "ones = np.ones((1,len(x_train)))\n",
    "X = np.hstack((ones.T ,x_train))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "id": "a7c6310f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta_hat [[-1.65926404e-02]\n",
      " [ 2.17327582e-02]\n",
      " [ 5.52578871e-04]\n",
      " [ 7.80913919e-02]\n",
      " [ 3.31357433e-01]\n",
      " [-6.81661406e-01]\n",
      " [ 1.69721957e+00]\n",
      " [ 4.98734472e-02]\n",
      " [ 1.81267959e+00]\n",
      " [ 7.78111741e-03]\n",
      " [-1.44714336e-02]\n",
      " [-1.45742338e+00]\n",
      " [-7.07007047e-01]\n",
      " [ 3.27382534e-02]\n",
      " [-6.17384811e-01]\n",
      " [ 6.92794585e-03]\n",
      " [-3.76264812e-01]\n",
      " [-1.29490509e-01]\n",
      " [-1.36598513e+00]\n",
      " [-1.27365158e+00]\n",
      " [ 9.58563665e-01]]\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "a7c6310f",
   "metadata": {},
   "outputs": [],
>>>>>>> 9c604b1 (initial commit)
   "source": [
    "# Beta = (X.T * X)^-1 * X.T * y\n",
    "Beta_hat = np.matmul(\n",
    "                np.matmul(\n",
    "                    np.linalg.inv(\n",
    "                        np.matmul(\n",
    "                            X.T\n",
    "                            ,X)\n",
    "                    ),\n",
    "                    X.T)\n",
    "                ,y_train)\n",
    "\n",
<<<<<<< HEAD
    "print(\"Beta_hat\", Beta_hat)"
=======
    "# print(\"Beta_hat\", Beta_hat)"
>>>>>>> 9c604b1 (initial commit)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e54f12f",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Squared Error"
=======
    "## Sum Squared Errors"
>>>>>>> 9c604b1 (initial commit)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "id": "d3d660b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE [[0.97261502]]\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "d3d660b9",
   "metadata": {},
   "outputs": [],
>>>>>>> 9c604b1 (initial commit)
   "source": [
    "SSE = np.matmul(\n",
    "    (y_train-np.matmul(X, Beta_hat)).T,\n",
    "    (y_train-np.matmul(X, Beta_hat))\n",
    ")\n",
    "print(\"SSE\", SSE)\n",
    "# mse"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba91822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.7 MB 7.6 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=1.1.0\n",
      "  Downloading scipy-1.7.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.5 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /usr/lib/python3.9/site-packages (from scikit-learn) (1.21.2)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.0 scipy-1.7.1 threadpoolctl-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
=======
   "cell_type": "markdown",
   "id": "4379dfba",
   "metadata": {},
   "source": [
    "## Model Class"
>>>>>>> 9c604b1 (initial commit)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": null,
>>>>>>> 9c604b1 (initial commit)
   "id": "661a79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearPredictor():\n",
    "    def train(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Train the model and set Beta_hat\n",
    "        \"\"\"\n",
    "        ones = np.ones((1,len(x_train)))\n",
    "        X = np.hstack((ones.T ,x_train))\n",
    "        \n",
<<<<<<< HEAD
    "        \"\"\"\n",
    "        step1 = np.matmul(X.T,X)\n",
    "        step2 = np.linalg.inv(step1)\n",
    "        step3 = np.matmul(step2,X.T)\n",
    "        self.Beta_hat = np.matmul(step3,y_train)\n",
    "        \n",
    "        # self.Beta_hat = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.T,X)),X.T),y_train)\n",
    "        \"\"\"\n",
=======
    "        # self.Beta_hat = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.T,X)),X.T),y_train)\n",
>>>>>>> 9c604b1 (initial commit)
    "        self.Beta_hat = np.matmul(\n",
    "                np.matmul(\n",
    "                    np.linalg.inv(\n",
    "                        np.matmul(\n",
    "                            X.T\n",
    "                            ,X)\n",
    "                    ),\n",
    "                    X.T)\n",
    "                ,y_train)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def perf(self, x_test, y_test):\n",
    "        \"\"\"\n",
    "        Calc sum of squares error for test set\n",
    "        Set SSE\n",
    "        \"\"\"\n",
    "        ones = np.ones((1,len(x_test)))\n",
    "        X = np.hstack((ones.T ,x_test))\n",
    "\n",
    "        self.SSE = np.matmul(\n",
    "            (y_test-np.matmul(X, self.Beta_hat)).T,\n",
    "            (y_test-np.matmul(X, self.Beta_hat))\n",
    "        )\n",
    "        return self.SSE\n",
    "    \n",
<<<<<<< HEAD
    "    def __call__(self, x_0):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279155b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "145d7744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.26268051, -1.93113369, -0.15944778, -1.37890689, -0.50613778,\n",
       "        -0.96046102,  0.26348114,  1.19541748,  0.66006171, -0.24226576,\n",
       "        -0.82543447, -0.34835299, -0.70110232,  0.32584348, -0.13985143,\n",
       "        -0.61469867, -0.23648495,  0.39404187, -0.18641383,  0.56475771],\n",
       "       [ 0.97648954,  0.66029978,  2.70402605, -0.26017207, -0.98313707,\n",
       "         0.1302868 ,  0.6473359 , -1.70056968, -1.22956583,  0.54529207,\n",
       "         0.40426406, -1.78672292, -2.67789975, -0.27978277, -1.00191801,\n",
       "        -1.76933098, -0.74243655, -0.2738734 , -0.35648562,  0.5770167 ],\n",
       "       [ 0.97781504, -1.1025096 , -0.19849992,  0.99476817, -0.43722205,\n",
       "         0.89340998,  0.81426846, -0.5855486 , -0.57062764,  1.98063887,\n",
       "        -0.94127521,  0.96737518, -0.45541866,  0.86134619,  0.52297404,\n",
       "         0.08813147,  0.34526664, -1.95551832, -1.29437689,  1.4382038 ],\n",
       "       [ 1.17002111, -0.10297064, -0.14140461,  1.83403368,  1.64072849,\n",
       "         0.34833828, -0.70909259,  2.20556466, -0.68222781,  0.11110242,\n",
       "         0.92484276, -0.4395795 , -0.10866414, -0.0368973 ,  0.56861793,\n",
       "        -0.60000047, -1.07229482,  0.17978873,  0.3742515 , -0.56956627],\n",
       "       [ 0.15931086, -1.05980154,  0.41126793, -1.71591032,  0.53036656,\n",
       "         0.76043265, -0.66999223, -0.82722031,  0.25456186,  3.53365754,\n",
       "        -0.46859349, -0.55813808,  0.27561734, -1.31317389,  0.13523533,\n",
       "         1.11670504,  0.32117405, -1.17598796,  1.05532722,  2.37190688],\n",
       "       [ 0.49952085, -1.23856594, -1.17905966,  0.08693171, -2.12237815,\n",
       "        -0.91596242, -0.98887504,  1.96607527,  0.13169225, -1.00099383,\n",
       "        -0.59598895, -0.24979719,  0.50734859,  0.43473874,  0.55751319,\n",
       "        -1.10227735, -0.67663537,  0.48333927, -0.26493617,  0.81604354],\n",
       "       [-1.05537507, -1.88923606, -0.27777551,  1.95567435, -0.8503778 ,\n",
       "         1.49040886,  1.03685174, -2.30118528,  1.64460294,  1.13481001,\n",
       "        -0.85925116,  0.95203624,  0.44479652,  0.89144742,  0.8828836 ,\n",
       "        -1.23725624, -0.75650561,  1.48808701,  0.44016791, -1.64458919],\n",
       "       [-0.4507432 , -0.97358455, -1.58105341,  0.16145377, -0.42409521,\n",
       "         2.14863569, -0.05783492, -0.99456301, -0.23605476,  0.75866303,\n",
       "        -0.0664302 ,  0.66139696,  0.16560227, -2.58789896,  2.40934926,\n",
       "         0.38964556, -0.44326531, -0.94133277,  0.10894438, -0.84636327],\n",
       "       [ 1.27037824,  0.21211584,  1.04902235, -0.62868836, -1.02959646,\n",
       "         1.12985334, -0.82325455,  0.10674079, -0.70698593,  0.29171624,\n",
       "         2.00135174,  0.30157358, -0.79666751,  0.2860868 ,  0.49517127,\n",
       "        -1.27001629,  0.11844371,  1.01440637, -0.12757854, -0.59361525],\n",
       "       [ 0.8986936 ,  0.49344199,  0.30268904, -1.43882447, -0.34903598,\n",
       "        -1.4344786 ,  1.95609942,  1.37514306, -0.58833124,  2.24527355,\n",
       "        -1.14332607, -0.67237021, -0.44798844,  1.35335936,  0.96869092,\n",
       "         0.23582185, -0.38277738, -0.99278411,  0.86893893, -1.4542976 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[-10:]"
=======
    "    def predict(self, x_0):\n",
    "        X_0 = np.hstack((np.ones(1).T ,x_0))\n",
    "        y_0 = np.matmul(self.Beta_hat.T, X_0)\n",
    "        return y_0\n",
    "    \n",
    "    def __call__(self, x_0):\n",
    "        return self.predict(x_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44170711",
   "metadata": {},
   "source": [
    "## Cross Validation"
>>>>>>> 9c604b1 (initial commit)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "id": "c761d18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_ 0 0.12520788995320348\n",
      "P_ 1 0.2719329646216435\n",
      "P_ 2 0.19795052583200332\n",
      "P_ 3 0.12071540279951451\n",
      "P_ 4 0.2408444670347426\n",
      "P_ 5 0.10136302837185727\n",
      "P_ 6 0.11471550902071387\n",
      "P_ 7 0.12607840569432624\n",
      "P_ 8 0.08158948951907509\n",
      "P_ 9 0.24453697979376293\n",
      "avg(P) 0.16249346626408429\n",
      "f.Beta_hat [[-1.65926404e-02]\n",
      " [ 2.17327582e-02]\n",
      " [ 5.52578871e-04]\n",
      " [ 7.80913919e-02]\n",
      " [ 3.31357433e-01]\n",
      " [-6.81661406e-01]\n",
      " [ 1.69721957e+00]\n",
      " [ 4.98734472e-02]\n",
      " [ 1.81267959e+00]\n",
      " [ 7.78111741e-03]\n",
      " [-1.44714336e-02]\n",
      " [-1.45742338e+00]\n",
      " [-7.07007047e-01]\n",
      " [ 3.27382534e-02]\n",
      " [-6.17384811e-01]\n",
      " [ 6.92794585e-03]\n",
      " [-3.76264812e-01]\n",
      " [-1.29490509e-01]\n",
      " [-1.36598513e+00]\n",
      " [-1.27365158e+00]\n",
      " [ 9.58563665e-01]]\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "c761d18f",
   "metadata": {},
   "outputs": [],
>>>>>>> 9c604b1 (initial commit)
   "source": [
    "p = np.zeros(10)\n",
    "\n",
    "x = x_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
<<<<<<< HEAD
    "#for n,m in zip([0,1,2,3,4,5,6,7,8,9], [9,0,1,2,3,4,5,6,7,8]):\n",
    "for n in range(10):\n",
=======
    "for n in range(10):\n",
    "    # rotate\n",
>>>>>>> 9c604b1 (initial commit)
    "    x = np.vstack((x[-10:], x[0:-10]))\n",
    "    y = np.vstack((y[-10:], y[0:-10]))\n",
    "    \n",
    "    x_train_n = x[0: -10]\n",
    "    y_train_n = y[0: -10]\n",
    "    \n",
    "    x_validation_n = x[-10:]\n",
    "    y_validation_n = y[-10:]\n",
    "    \n",
    "    f_n = LinearPredictor()\n",
    "    f_n.train(x_train_n, y_train_n)\n",
    "    p[n] = f_n.perf(x_validation_n, y_validation_n)\n",
    "    print(\"P_\", n ,p[n])\n",
    "\n",
    "print(\"avg(P)\", np.average(p))\n",
    "f = LinearPredictor()\n",
    "f.train(x_train, y_train)\n",
<<<<<<< HEAD
    "print(\"f.Beta_hat\", f.Beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac229e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.matrix([[3, 90],\n",
    "               [90, 2772]])\n",
    "\n",
    "B = np.matrix([[43, 1308]]).transpose()\n",
    "\n",
    "Beta = np.linalg.solve(A,B)\n",
    "print(\"Beta\", Beta)\n",
    "# Validate solution is a minimum\n",
    "H = 2* np.matrix([[3,  90], [90, 2772]])\n",
    "# if H is positive definite matrix\n",
    "# positive determinant\n",
    "print(np.linalg.det(H))\n",
    "# positive and real eigenvalues\n",
    "print(np.linalg.eigvals(H))\n",
    "\n",
    "# Equation\n",
    "# Calc SSE\n",
    "\n",
    "# Normal equations\n",
    "x = np.array([24, 30, 36]).T\n",
    "# remember X = [1 x.T]\n",
    "X = np.vstack([np.ones(3).T,x]).T\n",
    "\n",
    "Y = np.array([13, 14, 16]).T\n",
    "\n",
    "Beta_hat = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.T,X)),X.T),Y)\n",
    "print(\"Beta_hat\", Beta_hat)\n",
    "SSE = np.matmul((Y-np.matmul(X, Beta)).T,(Y-np.matmul(X,Beta)))\n",
    "print(\"SSE\", SSE)\n",
    "\n",
    "for X_0 in [9, 25, 34]:\n",
    "    f_X_0 = np.matmul(np.matrix([1, X_0]), Beta)\n",
    "    print(X_0, f_X_0)\n",
    "\n",
    "for X_0 in [9, 25, 34]:\n",
    "    f_X_0 = np.matmul(np.matrix([1, X_0]), Beta_hat)\n",
    "    print(X_0, f_X_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e57029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
=======
    "print(\"f.Beta_hat\", f.Beta_hat)\n",
    "y_0 = f.predict(x_test[0])\n",
    "print(\"f(x_test[0])\", y_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9099715b",
   "metadata": {},
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520f07a",
   "metadata": {},
   "source": [
    "### Linerar"
>>>>>>> 9c604b1 (initial commit)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": null,
>>>>>>> 9c604b1 (initial commit)
   "id": "cdb7ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
<<<<<<< HEAD
    "\n",
=======
>>>>>>> 9c604b1 (initial commit)
    "lin = LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "id": "aa3c8f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993581999313677"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "id": "aa3c8f07",
   "metadata": {},
   "outputs": [],
>>>>>>> 9c604b1 (initial commit)
   "source": [
    "s = lin.score(x_train, y_train)\n",
    "print(\"Linear\", s)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 21,
=======
   "cell_type": "markdown",
   "id": "7860c5f3",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> 9c604b1 (initial commit)
   "id": "b7916a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
   "id": "17a13b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rid 0 0.9993581999313677\n",
      "Rid 1 0.9992449134418986\n",
      "Rid 2 0.998918629130674\n",
      "Rid 3 0.9983981133565093\n",
      "Rid 4 0.9977002214558892\n",
      "Rid 5 0.9968401351166853\n",
      "Rid 6 0.9958315646290027\n",
      "Rid 7 0.9946869220326288\n",
      "Rid 8 0.9934174700134569\n",
      "Rid 9 0.9920334504854623\n",
      "Rid 10 0.9905441960710747\n",
      "Rid 11 0.9889582271170045\n",
      "Rid 12 0.9872833364215858\n",
      "Rid 13 0.9855266634784081\n",
      "Rid 14 0.9836947597402766\n",
      "Rid 15 0.9817936461626384\n",
      "Rid 16 0.9798288640851732\n",
      "Rid 17 0.9778055203453875\n",
      "Rid 18 0.9757283273818388\n",
      "Rid 19 0.9736016389715751\n",
      "Rid 20 0.9714294821521612\n",
      "Rid 21 0.9692155857998368\n",
      "Rid 22 0.9669634062691357\n",
      "Rid 23 0.9646761504434692\n",
      "Rid 24 0.9623567964989524\n",
      "Rid 25 0.9600081126436532\n",
      "Rid 26 0.9576326740602982\n",
      "Rid 27 0.9552328782513004\n",
      "Rid 28 0.9528109589599674\n",
      "Rid 29 0.9503689988202719\n",
      "Rid 30 0.9479089408690492\n",
      "Rid 31 0.9454325990384891\n",
      "Rid 32 0.9429416677329308\n",
      "Rid 33 0.9404377305819352\n",
      "Rid 34 0.9379222684511275\n",
      "Rid 35 0.9353966667831626\n",
      "Rid 36 0.932862222333172\n",
      "Rid 37 0.9303201493560385\n",
      "Rid 38 0.9277715852966969\n",
      "Rid 39 0.9252175960292377\n",
      "Rid 40 0.9226591806858212\n",
      "Rid 41 0.920097276112185\n",
      "Rid 42 0.9175327609828008\n",
      "Rid 43 0.9149664596054214\n",
      "Rid 44 0.9123991454418222\n",
      "Rid 45 0.9098315443689259\n",
      "Rid 46 0.9072643377021683\n",
      "Rid 47 0.9046981650008853\n",
      "Rid 48 0.9021336266736409\n",
      "Rid 49 0.8995712863997543\n",
      "Rid 50 0.8970116733817911\n",
      "Rid 51 0.8944552844424484\n",
      "Rid 52 0.8919025859780544\n",
      "Rid 53 0.8893540157798283\n",
      "Rid 54 0.8868099847330639\n",
      "Rid 55 0.884270878403521\n",
      "Rid 56 0.8817370585195173\n",
      "Rid 57 0.8792088643574885\n",
      "Rid 58 0.8766866140381342\n",
      "Rid 59 0.8741706057396821\n",
      "Rid 60 0.8716611188342549\n",
      "Rid 61 0.8691584149528521\n",
      "Rid 62 0.8666627389840014\n",
      "Rid 63 0.8641743200107448\n",
      "Rid 64 0.8616933721902438\n",
      "Rid 65 0.8592200955799646\n",
      "Rid 66 0.8567546769140891\n",
      "Rid 67 0.8542972903335239\n",
      "Rid 68 0.8518480980726196\n",
      "Rid 69 0.8494072511054812\n",
      "Rid 70 0.8469748897545331\n",
      "Rid 71 0.8445511442638078\n",
      "Rid 72 0.8421361353392464\n",
      "Rid 73 0.8397299746581279\n",
      "Rid 74 0.8373327653496031\n",
      "Rid 75 0.8349446024481536\n",
      "Rid 76 0.8325655733216801\n",
      "Rid 77 0.8301957580757979\n",
      "Rid 78 0.827835229935809\n",
      "Rid 79 0.8254840556077193\n",
      "Rid 80 0.8231422956195769\n",
      "Rid 81 0.8208100046443185\n",
      "Rid 82 0.8184872318052336\n",
      "Rid 83 0.8161740209650769\n",
      "Rid 84 0.8138704109998006\n",
      "Rid 85 0.8115764360578039\n",
      "Rid 86 0.809292125805545\n",
      "Rid 87 0.8070175056603026\n",
      "Rid 88 0.804752597010828\n",
      "Rid 89 0.8024974174265758\n",
      "Rid 90 0.8002519808561587\n",
      "Rid 91 0.7980162978156402\n",
      "Rid 92 0.7957903755672231\n",
      "Rid 93 0.7935742182888765\n",
      "Rid 94 0.7913678272353952\n",
      "Rid 95 0.7891712008913654\n",
      "Rid 96 0.7869843351164756\n",
      "Rid 97 0.784807223283588\n",
      "Rid 98 0.7826398564099606\n",
      "Rid 99 0.780482223281987\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "17a13b17",
   "metadata": {},
   "outputs": [],
>>>>>>> 9c604b1 (initial commit)
   "source": [
    "for a in range(100):\n",
    "    rid = Ridge(alpha=a).fit(x_train, y_train)\n",
    "    s = rid.score(x_train, y_train)\n",
    "    print(\"Ridge\", a, s)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 28,
   "id": "4df6a382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso 0 0.9993581999313677\n",
      "Lasso 1 0.52414009356654\n",
      "Lasso 2 0.0\n",
      "Lasso 3 0.0\n",
      "Lasso 4 0.0\n",
      "Lasso 5 0.0\n",
      "Lasso 6 0.0\n",
      "Lasso 7 0.0\n",
      "Lasso 8 0.0\n",
      "Lasso 9 0.0\n",
      "Lasso 10 0.0\n",
      "Lasso 11 0.0\n",
      "Lasso 12 0.0\n",
      "Lasso 13 0.0\n",
      "Lasso 14 0.0\n",
      "Lasso 15 0.0\n",
      "Lasso 16 0.0\n",
      "Lasso 17 0.0\n",
      "Lasso 18 0.0\n",
      "Lasso 19 0.0\n",
      "Lasso 20 0.0\n",
      "Lasso 21 0.0\n",
      "Lasso 22 0.0\n",
      "Lasso 23 0.0\n",
      "Lasso 24 0.0\n",
      "Lasso 25 0.0\n",
      "Lasso 26 0.0\n",
      "Lasso 27 0.0\n",
      "Lasso 28 0.0\n",
      "Lasso 29 0.0\n",
      "Lasso 30 0.0\n",
      "Lasso 31 0.0\n",
      "Lasso 32 0.0\n",
      "Lasso 33 0.0\n",
      "Lasso 34 0.0\n",
      "Lasso 35 0.0\n",
      "Lasso 36 0.0\n",
      "Lasso 37 0.0\n",
      "Lasso 38 0.0\n",
      "Lasso 39 0.0\n",
      "Lasso 40 0.0\n",
      "Lasso 41 0.0\n",
      "Lasso 42 0.0\n",
      "Lasso 43 0.0\n",
      "Lasso 44 0.0\n",
      "Lasso 45 0.0\n",
      "Lasso 46 0.0\n",
      "Lasso 47 0.0\n",
      "Lasso 48 0.0\n",
      "Lasso 49 0.0\n",
      "Lasso 50 0.0\n",
      "Lasso 51 0.0\n",
      "Lasso 52 0.0\n",
      "Lasso 53 0.0\n",
      "Lasso 54 0.0\n",
      "Lasso 55 0.0\n",
      "Lasso 56 0.0\n",
      "Lasso 57 0.0\n",
      "Lasso 58 0.0\n",
      "Lasso 59 0.0\n",
      "Lasso 60 0.0\n",
      "Lasso 61 0.0\n",
      "Lasso 62 0.0\n",
      "Lasso 63 0.0\n",
      "Lasso 64 0.0\n",
      "Lasso 65 0.0\n",
      "Lasso 66 0.0\n",
      "Lasso 67 0.0\n",
      "Lasso 68 0.0\n",
      "Lasso 69 0.0\n",
      "Lasso 70 0.0\n",
      "Lasso 71 0.0\n",
      "Lasso 72 0.0\n",
      "Lasso 73 0.0\n",
      "Lasso 74 0.0\n",
      "Lasso 75 0.0\n",
      "Lasso 76 0.0\n",
      "Lasso 77 0.0\n",
      "Lasso 78 0.0\n",
      "Lasso 79 0.0\n",
      "Lasso 80 0.0\n",
      "Lasso 81 0.0\n",
      "Lasso 82 0.0\n",
      "Lasso 83 0.0\n",
      "Lasso 84 0.0\n",
      "Lasso 85 0.0\n",
      "Lasso 86 0.0\n",
      "Lasso 87 0.0\n",
      "Lasso 88 0.0\n",
      "Lasso 89 0.0\n",
      "Lasso 90 0.0\n",
      "Lasso 91 0.0\n",
      "Lasso 92 0.0\n",
      "Lasso 93 0.0\n",
      "Lasso 94 0.0\n",
      "Lasso 95 0.0\n",
      "Lasso 96 0.0\n",
      "Lasso 97 0.0\n",
      "Lasso 98 0.0\n",
      "Lasso 99 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11050/1752988664.py:4: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lass = Lasso(alpha=a).fit(x_train, y_train)\n",
      "/home/helder/.local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:645: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/helder/.local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:645: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.863e-01, tolerance: 1.515e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
=======
   "cell_type": "markdown",
   "id": "c9fbc5a7",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6a382",
   "metadata": {},
   "outputs": [],
>>>>>>> 9c604b1 (initial commit)
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for a in range(100):\n",
    "    lass = Lasso(alpha=a).fit(x_train, y_train)\n",
    "    s = lass.score(x_train, y_train)\n",
    "    print(\"Lasso\", a, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb54b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python39764bit341ff8accb5146f1b343ae3d10721a10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
